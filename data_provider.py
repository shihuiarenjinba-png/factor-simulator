import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import datetime
from scipy.stats import linregress
from concurrent.futures import ThreadPoolExecutor  # ã€è¿½åŠ ã€‘ä¸¦åˆ—å‡¦ç†ç”¨

# ---------------------------------------------------------
# 0. åŸºæœ¬è¨­å®š (Config)
# ---------------------------------------------------------
st.set_page_config(layout="wide", page_title="Market Factor Lab Pro (Modular)")

# åˆ†æžå¯¾è±¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒã™ã‚‹ãŸã‚æ®‹ã—ã¦ã„ã¾ã™ï¼‰
NIKKEI_225_SAMPLE = [
    "7203.T", "6758.T", "6861.T", "9984.T", "9983.T", "8035.T", "6098.T", "4063.T", "6367.T", "9432.T",
    "4502.T", "4503.T", "6501.T", "7267.T", "8058.T", "8001.T", "6954.T", "6981.T", "9020.T", "9022.T",
    "7741.T", "5108.T", "4452.T", "6902.T", "7974.T", "8031.T", "4519.T", "4568.T", "6273.T", "4543.T",
    "6702.T", "6503.T", "4901.T", "4911.T", "2502.T", "2802.T", "3382.T", "8306.T", "8316.T", "8411.T",
    "8766.T", "8591.T", "8801.T", "8802.T", "9021.T", "9101.T", "9433.T", "9434.T", "9501.T", "9502.T"
]

TOPIX_100_SAMPLE = [
    "7203.T", "6758.T", "8306.T", "9984.T", "8035.T", "9432.T", "6861.T", "9983.T", "4063.T", "8058.T",
    "6501.T", "8001.T", "6902.T", "4568.T", "8316.T", "8411.T", "8766.T", "9022.T", "6367.T", "4502.T",
    "6098.T", "7741.T", "6954.T", "4503.T", "6981.T", "5108.T", "4452.T", "7974.T", "8031.T", "4519.T"
]

# ---------------------------------------------------------
# ã€Modifiedã€‘Module 1: Data Provider (ä¸¦åˆ—å‡¦ç†ãƒ»é«˜é€ŸåŒ–ãƒ»å …ç‰¢ç‰ˆ)
# ---------------------------------------------------------
class DataProvider:
    """
    ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã‚’æ‹…å½“ã™ã‚‹ç‹¬ç«‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (v2.0 High-Speed)
    """

    @staticmethod
    def get_universe_tickers(mode="Nikkei 225"):
        """
        ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã«å¿œã˜ãŸéŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å‹•çš„ã«è¿”ã™ï¼ˆå°†æ¥çš„ãªæ‹¡å¼µç”¨ï¼‰
        """
        if "Nikkei" in mode:
            # å¿…è¦ã«å¿œã˜ã¦å…¨éŠ˜æŸ„ãƒªã‚¹ãƒˆãªã©ã‚’ã“ã“ã«è¨˜è¿°
            return NIKKEI_225_SAMPLE
        elif "TOPIX" in mode:
            return TOPIX_100_SAMPLE
        return []

    @staticmethod
    @st.cache_data(ttl=3600)  # 1æ™‚é–“ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿æŒ
    def fetch_fundamentals(tickers):
        """
        ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºæƒ…å ±ï¼ˆæ™‚ä¾¡ç·é¡ã€ROEã€PBRãªã©ï¼‰ã‚’ä¸¦åˆ—å‡¦ç†ã§é«˜é€Ÿå–å¾—
        """
        # é‡è¤‡å‰Šé™¤
        unique_tickers = list(set(tickers))
        
        # å†…éƒ¨é–¢æ•°: 1éŠ˜æŸ„ã”ã¨ã®å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
        def get_single_stock(ticker):
            try:
                tk = yf.Ticker(ticker)
                # fast_infoã§ã¯ãªãã€ã‚ˆã‚Šè©³ç´°ãª info ã‚’ä½¿ç”¨
                info = tk.info
                
                # ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€‘ å¿…é ˆãƒ‡ãƒ¼ã‚¿æ¬ æãƒã‚§ãƒƒã‚¯
                # ä¾¡æ ¼æƒ…å ±ãŒå–ã‚Œãªã„ã‚‚ã®ã¯ã€ä¸Šå ´å»ƒæ­¢ã‚„ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ãŒé«˜ã„ãŸã‚é™¤å¤–
                if info is None or 'currentPrice' not in info or info['currentPrice'] is None:
                    return None
                
                return {
                    'Ticker': ticker,
                    'Name': info.get('shortName', ticker),
                    'Price': info.get('currentPrice', np.nan),
                    'Size_Raw': info.get('marketCap', np.nan),
                    'PBR': info.get('priceToBook', np.nan),     # Valueç”¨
                    'ROE': info.get('returnOnEquity', np.nan),  # Qualityç”¨
                    'Growth': info.get('revenueGrowth', np.nan) # Investmentç”¨
                }
            except Exception:
                # å–å¾—å¤±æ•—æ™‚ã¯Noneã‚’è¿”ã—ã€å¾Œã§ãƒªã‚¹ãƒˆã‹ã‚‰é™¤å¤–ã™ã‚‹
                return None

        # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ (æœ€å¤§20ã‚¹ãƒ¬ãƒƒãƒ‰ã§åŒæ™‚å–å¾—)
        results = []
        # UXå‘ä¸Šã®ãŸã‚spinnerã¯å‘¼ã³å‡ºã—å…ƒã§åˆ¶å¾¡æŽ¨å¥¨ã ãŒã€ã“ã“ã§ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†
        with ThreadPoolExecutor(max_workers=20) as executor:
            # mapã¯å…¥åŠ›é †åºã‚’ä¿æŒã™ã‚‹
            fetched_data = list(executor.map(get_single_stock, unique_tickers))
        
        # None (å–å¾—å¤±æ•—) ã‚’ãƒªã‚¹ãƒˆã‹ã‚‰é™¤å¤–
        results = [d for d in fetched_data if d is not None]

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)
        
        # æ•°å€¤åž‹ã®å¼·åˆ¶å¤‰æ›ï¼ˆå¿µã®ãŸã‚ã‚¨ãƒ©ãƒ¼å›žé¿ï¼‰
        num_cols = ['Price', 'Size_Raw', 'PBR', 'ROE', 'Growth']
        for c in num_cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors='coerce')

        return df

    @staticmethod
    @st.cache_data(ttl=86400) # ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯1æ—¥ä¿æŒ
    def fetch_historical_prices(tickers, days=365):
        """
        ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæ ªä¾¡æŽ¨ç§»ï¼‰ã‚’ä¸€æ‹¬å–å¾— (v2.0 Robust)
        """
        end_date = datetime.datetime.now()
        start_date = end_date - datetime.timedelta(days=days)
        
        if not tickers:
            return pd.DataFrame()

        try:
            # yf.downloadã¯å†…éƒ¨ã§ãƒžãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚é«˜é€Ÿ
            # group_by='ticker' ã§æ§‹é€ ã‚’å›ºå®šåŒ–
            df = yf.download(tickers, start=start_date, end=end_date, progress=False, group_by='ticker', auto_adjust=True)
            
            # DataFrameæ§‹é€ ã®æ­£è¦åŒ–
            if len(tickers) == 1:
                # 1éŠ˜æŸ„ã®å ´åˆ: Index=Date, Columns=[Open, High, Low, Close...]
                ticker = tickers[0]
                # 'Close'åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                if 'Close' in df.columns:
                    return pd.DataFrame({ticker: df['Close']})
                else:
                    return pd.DataFrame() # ãƒ‡ãƒ¼ã‚¿ãªã—
            else:
                # è¤‡æ•°éŠ˜æŸ„ã®å ´åˆ: MultiIndex (Ticker, OHLC) -> (Ticker, Close) ã‚’æŠ½å‡º
                try:
                    # xsã‚’ä½¿ã£ã¦ 'Close' ãƒ¬ãƒ™ãƒ«ã‚’æŠ½å‡º (axis=1)
                    df_close = df.xs('Close', axis=1, level=1, drop_level=True)
                    return df_close
                except KeyError:
                    # ã¾ã‚Œã«æ§‹é€ ãŒé•ã†å ´åˆã‚„ãƒ‡ãƒ¼ã‚¿æ¬ æã¸ã®å¯¾ç­–
                    return pd.DataFrame()
                    
        except Exception as e:
            st.error(f"Historical Data Error: {e}")
            return pd.DataFrame()

# ---------------------------------------------------------
# Module 2 & 3: Logic & Engine (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã®ç§»æ¤)
# ---------------------------------------------------------

def compute_derived_metrics(df_fund, df_hist, benchmark_ticker):
    """
    ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ Beta, Momentum, Value(é€†æ•°), Size(å¯¾æ•°) ã‚’è¨ˆç®—
    """
    df = df_fund.copy()
    
    # 1. Value (PBRã®é€†æ•°)
    df['Value_Raw'] = df['PBR'].apply(lambda x: 1/x if (pd.notnull(x) and x > 0) else np.nan)
    
    # 2. Size (å¯¾æ•°æ­£è¦åŒ–)
    df['Size_Log'] = np.log(pd.to_numeric(df['Size_Raw'], errors='coerce').replace(0, np.nan))
    
    # 3. Momentum & Beta
    moms = {}
    betas = {}
    
    if not df_hist.empty:
        # ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        rets = df_hist.pct_change().dropna()
        
        if benchmark_ticker in rets.columns:
            bench_ret = rets[benchmark_ticker]
            bench_var = bench_ret.var()
            
            # Beta Loop
            for t in df['Ticker']:
                if t in rets.columns:
                    # Beta
                    cov = rets[t].cov(bench_ret)
                    betas[t] = cov / bench_var if bench_var != 0 else 1.0
                    
                    # Momentum (éŽåŽ»1å¹´ã®ãƒªã‚¿ãƒ¼ãƒ³ç´¯ç©)
                    # ç°¡æ˜“çš„ã« (æœ€çµ‚ä¾¡æ ¼ / æœ€åˆä¾¡æ ¼) - 1
                    try:
                        p_end = df_hist[t].iloc[-1]
                        p_start = df_hist[t].iloc[0]
                        moms[t] = (p_end / p_start) - 1
                    except:
                        moms[t] = np.nan
                else:
                    betas[t] = 1.0
                    moms[t] = np.nan
        else:
            # ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
            for t in df['Ticker']:
                betas[t] = 1.0
                moms[t] = np.nan
                
    df['Beta_Raw'] = df['Ticker'].map(betas)
    df['Momentum_Raw'] = df['Ticker'].map(moms)
    
    # Rename columns to match logic
    df.rename(columns={'ROE': 'Quality_Raw', 'Growth': 'Investment_Raw'}, inplace=True)
    
    return df

def calculate_market_stats(universe_df):
    """
    ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹å…¨ä½“ã®å¹³å‡(mu)ã¨æ¨™æº–åå·®(sigma)ã‚’è¨ˆç®— + ç›´äº¤åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    """
    stats = {}
    
    # ç›´äº¤åŒ– (Quality vs Investment)
    mask = universe_df['Quality_Raw'].notna() & universe_df['Investment_Raw'].notna()
    if mask.sum() > 10:
        slope, intercept, _, _, _ = linregress(universe_df.loc[mask, 'Investment_Raw'], universe_df.loc[mask, 'Quality_Raw'])
    else:
        slope, intercept = 0, 0
    
    stats['ortho_slope'] = slope
    stats['ortho_intercept'] = intercept
    
    # å„ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®çµ±è¨ˆé‡
    factors = {
        'Beta': 'Beta_Raw',
        'Size': 'Size_Log',
        'Value': 'Value_Raw',
        'Momentum': 'Momentum_Raw',
        'Quality': 'Quality_Raw', # â€»è¨ˆç®—æ™‚ã«ç›´äº¤åŒ–ã™ã‚‹ãŒã€å…ƒãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚‚ä¸€å¿œä¿æŒ
        'Investment': 'Investment_Raw'
    }
    
    # Qualityã®ç›´äº¤åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ™‚ä½œæˆï¼ˆçµ±è¨ˆé‡è¨ˆç®—ç”¨ï¼‰
    temp_q = universe_df.apply(lambda x: x['Quality_Raw'] - (slope * x['Investment_Raw'] + intercept) 
                               if (pd.notnull(x['Quality_Raw']) and pd.notnull(x['Investment_Raw'])) else np.nan, axis=1)
    
    for f, col in factors.items():
        if f == 'Quality':
            series = temp_q.dropna()
        else:
            series = universe_df[col].dropna()
            
        if not series.empty:
            stats[f] = {'mean': series.mean(), 'std': series.std(), 'col': col}
        else:
            stats[f] = {'mean': 0, 'std': 1, 'col': col}
            
    return stats

def apply_scoring(target_df, stats):
    """
    Zã‚¹ã‚³ã‚¢è¨ˆç®— & SMBåè»¢ & ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ
    """
    df = target_df.copy()
    
    # ç›´äº¤åŒ–é©ç”¨
    slope = stats['ortho_slope']
    intercept = stats['ortho_intercept']
    df['Quality_Orthogonal'] = df.apply(lambda x: x['Quality_Raw'] - (slope * x['Investment_Raw'] + intercept) 
                                        if (pd.notnull(x['Quality_Raw']) and pd.notnull(x['Investment_Raw'])) else x['Quality_Raw'], axis=1)

    factors = ['Beta', 'Value', 'Size', 'Momentum', 'Quality', 'Investment']
    
    for f in factors:
        if f not in stats: continue
        
        # å‚ç…§ã‚«ãƒ©ãƒ ã®æ±ºå®š
        if f == 'Quality': col_name = 'Quality_Orthogonal'
        else: col_name = stats[f]['col']
            
        mu = stats[f]['mean']
        sigma = stats[f]['std']
        z_col = f"{f}_Z"
        
        # Zã‚¹ã‚³ã‚¢è¨ˆç®—
        def calc_z(val):
            if pd.isna(val): return 0.0
            if sigma == 0: return 0.0
            z = (val - mu) / sigma
            
            # ã€é‡è¦ã€‘SMBåè»¢: å¤§åž‹æ ª(Sizeå¤§)ã»ã©ãƒžã‚¤ãƒŠã‚¹ã‚¹ã‚³ã‚¢ã«ã™ã‚‹
            if f == 'Size':
                z = -z
            return z
            
        df[z_col] = df[col_name].apply(calc_z)
        
        # è¡¨ç¤ºç”¨ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ
        def fmt(row):
            raw = row.get(col_name)
            # ç”Ÿãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºç”¨ã«ã¯å…ƒã®Rawå€¤ã‚’ä½¿ã†å ´åˆã‚‚ã‚ã‚‹
            if f == 'Size': raw_disp = row.get('Size_Raw')
            elif f == 'Value': raw_disp = 1/raw if (raw and raw!=0) else np.nan # PBRã«æˆ»ã—ã¦è¡¨ç¤º
            else: raw_disp = raw
            
            z = row.get(z_col)
            
            if pd.isna(raw_disp): return "-"
            
            if f == 'Size':
                if raw_disp >= 1e12: txt = f"{raw_disp/1e12:.2f}å…†"
                elif raw_disp >= 1e8: txt = f"{raw_disp/1e8:.0f}å„„"
                else: txt = str(raw_disp)
            elif f in ['Momentum', 'Quality', 'Investment']:
                txt = f"{raw_disp*100:.1f}%"
            elif f == 'Value':
                txt = f"{raw_disp:.2f} (PBR)"
            else:
                txt = f"{raw_disp:.2f}"
                
            return f"{txt}\n({z:+.1f}Ïƒ)"
            
        df[f"{f}_Display"] = df.apply(fmt, axis=1)
        
    return df

# ---------------------------------------------------------
# 4. Main App (UI Integration)
# ---------------------------------------------------------

st.sidebar.header("1. Analysis Universe")
benchmark_mode = st.sidebar.radio("Compare against:", ["Nikkei 225 (Sample)", "TOPIX 100 (Sample)"])
selected_universe = NIKKEI_225_SAMPLE if "Nikkei" in benchmark_mode else TOPIX_100_SAMPLE
bench_ticker = "1321.T" if "Nikkei" in benchmark_mode else "1306.T"

st.sidebar.header("2. Portfolio Input")
st.sidebar.write("CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ã¾ãŸã¯ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›")
uploaded_file = st.sidebar.file_uploader("Upload CSV", type=['csv'])
default_tickers = "7203.T, 9984.T, 6758.T, 8035.T, 6861.T, 9983.T, 4502.T, 6367.T"
input_tickers = st.sidebar.text_area("Input Tickers", default_tickers, height=100)

if st.sidebar.button("Run Full Analysis", type="primary"):
    
    # A. å…¥åŠ›è§£æž
    input_data = []
    if uploaded_file:
        try:
            df_csv = pd.read_csv(uploaded_file)
            for _, row in df_csv.iterrows():
                input_data.append({'Ticker': str(row['Ticker']).strip(), 'Weight': row.get('Weight', np.nan)})
        except: st.error("CSV format error"); st.stop()
    else:
        for t in [x.strip() for x in input_tickers.split(',') if x.strip()]:
            input_data.append({'Ticker': t, 'Weight': np.nan})
    
    user_df_base = pd.DataFrame(input_data)
    user_tickers = user_df_base['Ticker'].tolist()
    
    # B. Module 1: ãƒ‡ãƒ¼ã‚¿å–å¾— (High-Speed & Parallel)
    with st.spinner("Fetching Market Data (Module 1)..."):
        # ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ + ãƒ¦ãƒ¼ã‚¶ãƒ¼éŠ˜æŸ„ + ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ETF
        all_tickers = list(set(selected_universe + user_tickers + [bench_ticker]))
        
        # 1. ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºå–å¾— (ä¸¦åˆ—å‡¦ç†)
        df_fund = DataProvider.fetch_fundamentals(all_tickers)
        
        # 2. ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«å–å¾—
        df_hist = DataProvider.fetch_historical_prices(all_tickers)
        
        if df_fund.empty:
            st.error("Data Fetch Failed.")
            st.stop()

    # C. Module 2: è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
    with st.spinner("Calculating Factors (Module 2)..."):
        # æŒ‡æ¨™è¨ˆç®— (Beta, LogSize, etc)
        df_full = compute_derived_metrics(df_fund, df_hist, bench_ticker)
        
        # ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹çµ±è¨ˆé‡ã®ç®—å‡º
        uni_df = df_full[df_full['Ticker'].isin(selected_universe)].copy()
        stats = calculate_market_stats(uni_df)
        
        # ãƒ¦ãƒ¼ã‚¶éŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        user_df_calc = df_full[df_full['Ticker'].isin(user_tickers)].copy()
        user_scored = apply_scoring(user_df_calc, stats)
        
        # ãƒžãƒ¼ã‚¸ã—ã¦ã‚¦ã‚§ã‚¤ãƒˆå¾©å…ƒ
        user_scored = pd.merge(user_scored, user_df_base, on='Ticker', how='left')
        
        # ã‚¦ã‚§ã‚¤ãƒˆè‡ªå‹•è£œå®Œ
        current_w = user_scored['Weight'].sum()
        nans = user_scored['Weight'].isna()
        if nans.any():
            rem = max(0, 100 - current_w)
            user_scored.loc[nans, 'Weight'] = rem / nans.sum()
        
    # D. çµæžœè¡¨ç¤º (UI)
    st.subheader("ðŸ›  Portfolio Composition")
    edited = st.data_editor(user_scored[['Ticker', 'Name', 'Weight']], 
                            column_config={"Weight": st.column_config.NumberColumn(format="%.2f%%")},
                            use_container_width=True)
    
    # ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—
    st.subheader("ðŸ§¬ Factor Heatmap")
    disp_cols = [c for c in user_scored.columns if "_Display" in c]
    
    def color_sigma(val):
        if "(" not in str(val): return ""
        try:
            sigma = float(val.split("(")[1].split("Ïƒ")[0])
            if sigma >= 1.0: return "background-color: #d1e7dd; color: #0f5132" # Green
            if sigma <= -1.0: return "background-color: #f8d7da; color: #842029" # Red
        except: pass
        return ""

    st.dataframe(user_scored[["Ticker", "Name"] + disp_cols].style.applymap(color_sigma), use_container_width=True)

    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    st.divider()
    w = edited['Weight'] / 100.0
    z_cols = [f"{f}_Z" for f in ['Beta', 'Size', 'Value', 'Momentum', 'Quality', 'Investment']]
    
    # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®åŠ é‡å¹³å‡Zã‚¹ã‚³ã‚¢
    port_exp = {}
    for zc in z_cols:
        port_exp[zc.replace("_Z", "")] = (user_scored[zc] * w).sum()
        
    st.bar_chart(pd.Series(port_exp))
    
    st.success("Analysis Complete using Modular Data Provider.")
