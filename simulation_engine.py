import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import statsmodels.api as sm
from statsmodels.regression.rolling import RollingOLS
from sklearn.decomposition import PCA
import pandas_datareader.data as web
from datetime import datetime

# =========================================================
# ğŸ› ï¸ ã‚¯ãƒ©ã‚¹å®šç¾© (Brain: V17.1 - Final Complete Edition)
# =========================================================

class MarketDataEngine:
    """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã€ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä¸€å…ƒç®¡ç†ã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ³"""
    def __init__(self):
        self.start_date = "2000-01-01"
        self.end_date = datetime.today().strftime('%Y-%m-%d')
        self.usdjpy_cache = None

    def validate_tickers(self, input_dict):
        """éŠ˜æŸ„ã®å­˜åœ¨ç¢ºèª"""
        valid_data = {}
        invalid_tickers = []
        status_text = st.empty()
        
        for ticker, weight in input_dict.items():
            try:
                tick = yf.Ticker(ticker)
                hist = tick.history(period="5d")
                if not hist.empty:
                    valid_data[ticker] = {'name': ticker, 'weight': weight}
                    status_text.text(f"âœ… OK: {ticker}")
                else:
                    invalid_tickers.append(ticker)
            except:
                invalid_tickers.append(ticker)
        
        status_text.empty()
        return valid_data, invalid_tickers

    def _get_usdjpy(self):
        """ç‚ºæ›¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ããƒ»æ§‹é€ åŒ–å¯¾å¿œï¼‰"""
        if self.usdjpy_cache is not None:
            return self.usdjpy_cache
        try:
            raw = yf.download("JPY=X", start=self.start_date, end=self.end_date, interval="1mo", auto_adjust=True, progress=False)
            if isinstance(raw, pd.DataFrame):
                if 'Close' in raw.columns:
                    usdjpy = raw['Close']
                else:
                    usdjpy = raw.iloc[:, 0]
            else:
                usdjpy = raw

            if isinstance(usdjpy, pd.DataFrame):
                usdjpy = usdjpy.iloc[:, 0]

            usdjpy = usdjpy.resample('M').last().ffill()
            if usdjpy.index.tz is not None: 
                usdjpy.index = usdjpy.index.tz_localize(None)
            
            self.usdjpy_cache = usdjpy
            return usdjpy
        except Exception:
            return pd.Series(dtype=float)

    @st.cache_data(ttl=3600*24*7)
    def fetch_french_factors(_self, region='US'):
        """ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰"""
        try:
            name = 'F-F_Research_Data_Factors'
            if region == 'Japan': 
                name = 'Japan_3_Factors'
            elif region == 'Global': 
                name = 'Global_3_Factors'

            ff_data = web.DataReader(name, 'famafrench', start=_self.start_date, end=_self.end_date)[0]
            ff_data = ff_data / 100.0
            
            ff_data.index = ff_data.index.to_timestamp(freq='M')
            if ff_data.index.tz is not None: 
                ff_data.index = ff_data.index.tz_localize(None)
            
            return ff_data
        except Exception:
            return pd.DataFrame()

    @st.cache_data(ttl=3600*24)
    def fetch_historical_prices(_self, tickers):
        """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰"""
        try:
            raw_data = yf.download(tickers, start=_self.start_date, end=_self.end_date, interval="1mo", auto_adjust=True, progress=False)
            data = pd.DataFrame()

            if len(tickers) == 1:
                ticker = tickers[0]
                if isinstance(raw_data, pd.Series):
                    data[ticker] = raw_data
                elif isinstance(raw_data, pd.DataFrame):
                    if 'Close' in raw_data.columns:
                        data[ticker] = raw_data['Close']
                    else:
                        data[ticker] = raw_data.iloc[:, 0]
            else:
                if isinstance(raw_data.columns, pd.MultiIndex):
                    try:
                        data = raw_data.xs('Close', axis=1, level=0, drop_level=True)
                    except KeyError:
                        try:
                            data = raw_data.xs('Adj Close', axis=1, level=0, drop_level=True)
                        except:
                            data = raw_data.iloc[:, :len(tickers)]
                            data.columns = tickers
                else:
                    data = raw_data

            data = data.resample('M').last().ffill()
            if data.index.tz is not None:
                data.index = data.index.tz_localize(None)

            usdjpy = _self._get_usdjpy()
            if not usdjpy.empty:
                usdjpy = usdjpy.reindex(data.index, method='ffill')
                data_jpy = data.copy()
                for col in data.columns:
                    is_japan = str(col).endswith(".T") or str(col) in ["^N225", "^TPX", "1306.T"]
                    if not is_japan:
                        data_jpy[col] = data[col] * usdjpy
            else:
                data_jpy = data

            returns = data_jpy.pct_change().dropna(how='all').dropna()
            valid_cols = [c for c in returns.columns if c in tickers]
            if valid_cols:
                returns = returns[valid_cols]
            
            return returns
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
            return pd.DataFrame()

    @st.cache_data(ttl=3600*24)
    def fetch_benchmark_data(_self, ticker, is_jpy_asset=False):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å–å¾—"""
        try:
            raw_data = yf.download(ticker, start=_self.start_date, end=_self.end_date, interval="1mo", auto_adjust=True, progress=False)
            data = pd.Series(dtype=float)
            if isinstance(raw_data, pd.DataFrame):
                if 'Close' in raw_data.columns:
                    data = raw_data['Close']
                elif isinstance(raw_data.columns, pd.MultiIndex):
                     try: data = raw_data.xs('Close', axis=1, level=0, drop_level=True)
                     except: data = raw_data.iloc[:, 0]
                else:
                    data = raw_data.iloc[:, 0]
            else:
                data = raw_data

            if isinstance(data, pd.DataFrame):
                data = data.iloc[:, 0]

            data = data.resample('M').last().ffill()
            if data.index.tz is not None:
                data.index = data.index.tz_localize(None)

            if not is_jpy_asset:
                usdjpy = _self._get_usdjpy()
                if not usdjpy.empty:
                    usdjpy = usdjpy.reindex(data.index, method='ffill')
                    data = data * usdjpy
            
            return data.pct_change().dropna()
        except:
            return pd.Series(dtype=float)

class PortfolioAnalyzer:
    
    @staticmethod
    def create_synthetic_history(returns_df, weights_dict):
        valid_tickers = [t for t in weights_dict.keys() if t in returns_df.columns]
        if not valid_tickers:
            return pd.Series(dtype=float), {}

        filtered_weights = {k: weights_dict[k] for k in valid_tickers}
        total_weight = sum(filtered_weights.values())
        norm_weights = {k: v/total_weight for k, v in filtered_weights.items()}
        
        weighted_returns = pd.DataFrame()
        for ticker, w in norm_weights.items():
            weighted_returns[ticker] = returns_df[ticker] * w
            
        port_ret = weighted_returns.sum(axis=1)
        return port_ret, norm_weights

    # --- ç›¸é–¢è¡Œåˆ—è¨ˆç®— ---
    @staticmethod
    def calculate_correlation_matrix(returns_df):
        """æ§‹æˆéŠ˜æŸ„ã®ç›¸é–¢è¡Œåˆ—ã‚’è¨ˆç®—"""
        if returns_df.empty:
            return pd.DataFrame()
        return returns_df.corr()

    # --- ğŸ”¥ [NEW] ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å›å¸°åˆ†æ (Style Analysis) ---
    @staticmethod
    def perform_factor_regression(port_ret, factor_df):
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’Fama-French 3ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã§å›å¸°åˆ†æã™ã‚‹"""
        if port_ret.empty or factor_df.empty:
            return None, None

        # ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“åˆã‚ã›
        df_y = port_ret.to_frame(name='y')
        df_y['period'] = df_y.index.to_period('M') 
        df_x = factor_df.copy()
        df_x['period'] = df_x.index.to_period('M') 
        
        merged = pd.merge(df_y, df_x, on='period', how='inner').dropna()
        if merged.empty: return None, None
        
        y = merged['y']
        # 'RF'ã¯ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆãªã®ã§ã€è¶…éãƒªã‚¿ãƒ¼ãƒ³(y - RF)ã‚’è¨ˆç®—ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ãŒã€
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã« Mkt-RF, SMB, HML ã‚’èª¬æ˜å¤‰æ•°ã¨ã—ã¦å›å¸°ã™ã‚‹
        X_cols = [c for c in merged.columns if c in ['Mkt-RF', 'SMB', 'HML']]
        X = merged[X_cols]
        X = sm.add_constant(X) # Alpha (const) ã‚’è¿½åŠ 

        try:
            model = sm.OLS(y, X)
            results = model.fit()
            return results.params, results.rsquared
        except:
            return None, None

    # --- ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (Fat-Tail Edition) ---
    @staticmethod
    def run_monte_carlo_simulation(port_ret, n_years=20, n_simulations=7500, initial_investment=1000000):
        if port_ret.empty:
            return None, None

        mu_monthly = port_ret.mean()
        sigma_monthly = port_ret.std()
        
        n_months = n_years * 12
        dt = 1/12
        
        drift = (mu_monthly - 0.5 * sigma_monthly**2)
        
        df_t = 6
        Z = np.random.standard_t(df_t, (n_months, n_simulations))
        
        daily_returns = np.exp(drift + sigma_monthly * Z)
        
        price_paths = np.zeros((n_months + 1, n_simulations))
        price_paths[0] = initial_investment
        price_paths[1:] = initial_investment * np.cumprod(daily_returns, axis=0)
        
        last_date = port_ret.index[-1]
        future_dates = pd.date_range(start=last_date, periods=n_months + 1, freq='M')
        
        percentiles = [10, 50, 90]
        stats_data = np.percentile(price_paths, percentiles, axis=1)
        df_stats = pd.DataFrame(stats_data.T, index=future_dates, columns=['p10', 'p50', 'p90'])
        
        final_values = price_paths[-1, :]
        
        return df_stats, final_values

    # --- æ—¢å­˜åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ ---
    @staticmethod
    def calculate_calmar_ratio(port_ret):
        if port_ret.empty: return np.nan
        cum_ret = (1 + port_ret).cumprod()
        if len(port_ret) < 12: return np.nan
        cagr = (cum_ret.iloc[-1])**(12/len(port_ret)) - 1
        max_dd = (cum_ret / cum_ret.cummax() - 1).min()
        if max_dd == 0: return np.nan
        return cagr / abs(max_dd)

    @staticmethod
    def calculate_omega_ratio(port_ret, threshold=0.0):
        if port_ret.empty: return np.nan
        gains = port_ret[port_ret > threshold] - threshold
        losses = threshold - port_ret[port_ret < threshold]
        sum_gains = gains.sum()
        sum_losses = losses.sum()
        if sum_losses == 0: return np.inf
        return sum_gains / sum_losses

    @staticmethod
    def calculate_information_ratio(port_ret, bench_ret):
        if port_ret.empty or bench_ret.empty: return np.nan, np.nan
        
        p_df = port_ret.to_frame(name='p')
        b_df = bench_ret.to_frame(name='b')
        p_df['period'] = p_df.index.to_period('M')
        b_df['period'] = b_df.index.to_period('M')
        
        merged = pd.merge(p_df, b_df, on='period', how='inner').dropna()
        
        if len(merged) < 12: return np.nan, np.nan
        
        active_ret = merged['p'] - merged['b']
        mean_active = active_ret.mean() * 12
        tracking_error = active_ret.std() * np.sqrt(12)
        if tracking_error == 0: return np.nan, 0.0
        return mean_active / tracking_error, tracking_error

    @staticmethod
    def perform_pca(returns_df):
        if returns_df.shape[1] < 2: return 1.0, None
        pca = PCA(n_components=2)
        pca.fit(returns_df)
        return pca.explained_variance_ratio_[0], pca

    @staticmethod
    def rolling_beta_analysis(port_ret, factor_df, window=24):
        if factor_df is None or factor_df.empty or port_ret.empty:
            return pd.DataFrame()

        df_y = port_ret.to_frame(name='y')
        df_y['period'] = df_y.index.to_period('M') 
        df_x = factor_df.copy()
        df_x['period'] = df_x.index.to_period('M') 
        
        merged = pd.merge(df_y, df_x, on='period', how='inner').dropna()
        if merged.empty: return pd.DataFrame()
        
        y = merged['y']
        X_cols = [c for c in merged.columns if c not in ['y', 'period']]
        X = merged[X_cols]
        
        data_len = len(y)
        if data_len < window:
            window = max(6, int(data_len / 2))
        if data_len < window:
            return pd.DataFrame()

        try:
            X_const = sm.add_constant(X)
            model = RollingOLS(y, X_const, window=window)
            rres = model.fit()
            params = rres.params.copy()
            if 'const' in params.columns:
                params = params.drop(columns=['const'])
            return params.dropna()
        except:
            return pd.DataFrame()

    @staticmethod
    def cost_drag_simulation(port_ret, cost_tier):
        if port_ret.empty: return pd.Series(), pd.Series(), 0, 0
        cost_map = {'Low': 0.001, 'Medium': 0.006, 'High': 0.020}
        annual_cost = cost_map.get(cost_tier, 0.006)
        monthly_cost = (1 + annual_cost)**(1/12) - 1
        net_ret = port_ret - monthly_cost
        gross_cum = (1 + port_ret).cumprod()
        net_cum = (1 + net_ret).cumprod()
        return gross_cum, net_cum, gross_cum.iloc[-1] - net_cum.iloc[-1], annual_cost

    @staticmethod
    def calculate_strict_attribution(returns_df, weights_dict):
        assets = list(weights_dict.keys())
        available_assets = [a for a in assets if a in returns_df.columns]
        if not available_assets: return pd.Series(dtype=float)
            
        w_series = pd.Series(weights_dict)
        total_w = w_series[available_assets].sum()
        initial_w = w_series[available_assets] / total_w
        
        r_df = returns_df[available_assets].copy()
        
        cum_r_index = (1 + r_df).cumprod()
        asset_values = cum_r_index.multiply(initial_w, axis=1)
        port_values = asset_values.sum(axis=1)
        
        weights_df = asset_values.div(port_values, axis=0).shift(1)
        weights_df.iloc[0] = initial_w
        
        port_ret = (weights_df * r_df).sum(axis=1)
        total_cum_ret = (1 + port_ret).prod() - 1
        
        log_return = np.log(1 + total_cum_ret)
        k = log_return / total_cum_ret if total_cum_ret != 0 else 1.0
            
        kt = np.log(1 + port_ret) / port_ret
        kt = kt.fillna(1.0)
        
        term = weights_df * r_df
        smoothed_term = term.multiply(kt, axis=0)
        
        final_attribution = smoothed_term.sum() / k
        
        return final_attribution.sort_values(ascending=True)

class PortfolioDiagnosticEngine:
    @staticmethod
    def generate_report(weights_dict, pca_ratio, port_ret, benchmark_ret=None):
        report = {
            "type": "",
            "risk_comment": "",
            "diversification_comment": "",
            "action_plan": ""
        }
        
        num_assets = len(weights_dict)
        
        if num_assets == 1:
            report["type"] = "ğŸ¹ é›†ä¸­æŠ•è³‡å‹ (Sniper Allocation)"
            report["diversification_comment"] = "ç¾åœ¨ã€1ã¤ã®éŠ˜æŸ„ã«å…¨ã¦ã®è³‡é‡‘ã‚’æŠ•ã˜ã¦ã„ã¾ã™ã€‚åˆ†æ•£åŠ¹æœã¯ä¸€åˆ‡æ©Ÿèƒ½ã—ã¦ã„ã¾ã›ã‚“ã€‚"
            report["risk_comment"] = "âš ï¸ å€‹åˆ¥æ ªãƒªã‚¹ã‚¯ãŒæœ€å¤§åŒ–ã—ã¦ã„ã¾ã™ã€‚"
            report["action_plan"] = "å°‘ãªãã¨ã‚‚å‹•ãã®ç•°ãªã‚‹3ã€œ5éŠ˜æŸ„ã¸ã®åˆ†æ•£ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
        else:
            if pca_ratio >= 0.85:
                report["type"] = "âš ï¸ è¦‹ã‹ã‘ã®åˆ†æ•£ (High Correlation)"
                report["diversification_comment"] = f"å…¨ä½“ã®å‹•ãã®{pca_ratio*100:.1f}%ãŒã€Œå…±é€šã®è¦å› ã€ã§èª¬æ˜ã§ãã¦ã—ã¾ã„ã¾ã™ã€‚"
                report["risk_comment"] = "å…¨éŠ˜æŸ„ãŒåŒæ™‚ã«ä¸‹è½ã™ã‚‹ã€Œå…±å€’ã‚Œã€ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„çŠ¶æ…‹ã§ã™ã€‚"
                report["action_plan"] = "æ ªå¼ã¨ã¯ç•°ãªã‚‹å‹•ãã‚’ã™ã‚‹è³‡ç”£ï¼ˆå›½å‚µã€ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ï¼‰ã‚’çµ„ã¿å…¥ã‚Œã¦ãã ã•ã„ã€‚"
            elif pca_ratio <= 0.60:
                report["type"] = "ğŸ° è¦å¡å‹åˆ†æ•£ (True Diversification)"
                report["diversification_comment"] = f"èª¬æ˜åŠ›ãŒ{pca_ratio*100:.1f}%ã¨ä½ãã€ç†æƒ³çš„ãªåˆ†æ•£åŠ¹æœãŒç™ºæ®ã•ã‚Œã¦ã„ã¾ã™ã€‚"
                report["risk_comment"] = "å¸‚å ´å…¨ä½“ã®ãƒªã‚¹ã‚¯ä»¥å¤–ã®ç„¡é§„ãªãƒªã‚¹ã‚¯ã¯æ’é™¤ã•ã‚Œã¦ã„ã¾ã™ã€‚"
                report["action_plan"] = "ç¾åœ¨ã®ãƒãƒ©ãƒ³ã‚¹ã¯éå¸¸ã«è‰¯å¥½ã§ã™ã€‚å®šæœŸçš„ãªãƒªãƒãƒ©ãƒ³ã‚¹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
            else:
                report["type"] = "âš–ï¸ æ¨™æº–åˆ†æ•£å‹ (Balanced)"
                report["diversification_comment"] = f"èª¬æ˜åŠ›ã¯{pca_ratio*100:.1f}%ã§ã€é©åº¦ãªåˆ†æ•£ãŒåŠ¹ã„ã¦ã„ã¾ã™ã€‚"
                report["risk_comment"] = "å¸‚å ´å¹³å‡ã«è¿‘ã„å‹•ãã‚’ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚"
                report["action_plan"] = "ã•ã‚‰ã«å®ˆã‚Šã‚’å›ºã‚ã‚‹ãªã‚‰å‚µåˆ¸æ¯”ç‡ã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"

        return report

    @staticmethod
    def get_skew_kurt_desc(port_ret):
        if port_ret.empty: return "ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚è¨ºæ–­ã§ãã¾ã›ã‚“ã€‚"
        skew = port_ret.skew()
        kurt = port_ret.kurt()
        desc = []
        if skew < -0.5: desc.append("âš ï¸ å·¦ã«è£¾ãŒé•·ã„åˆ†å¸ƒã§ã™ï¼ˆã‚³ãƒ„ã‚³ãƒ„ãƒ‰ã‚«ãƒ³å‹ï¼‰ã€‚")
        elif skew > 0.5: desc.append("âœ… å³ã«è£¾ãŒé•·ã„åˆ†å¸ƒã§ã™ï¼ˆå®ãã˜å‹ï¼‰ã€‚")
        if kurt > 2.0: desc.append("âš ï¸ æ¥µç«¯ãªå€¤å‹•ãï¼ˆãƒ•ã‚¡ãƒƒãƒˆãƒ†ãƒ¼ãƒ«ï¼‰ãŒèµ·ãã‚„ã™ã„æ§‹é€ ã§ã™ã€‚")
        return " ".join(desc) if desc else "åˆ†å¸ƒã«æ¥µç«¯ãªåã‚Šã¯ãªãã€çµ±è¨ˆçš„ã«ç´ ç›´ãªæŒ™å‹•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"

    # --- ğŸ”¥ [NEW] ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è§£èª¬ç”Ÿæˆ ---
    @staticmethod
    def generate_factor_report(params):
        """å›å¸°åˆ†æçµæœï¼ˆBetaï¼‰ã‹ã‚‰ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨€èªåŒ–ã™ã‚‹"""
        if params is None: return "åˆ†æä¸èƒ½"
        
        comments = []
        
        # 1. HML (ãƒãƒªãƒ¥ãƒ¼ vs ã‚°ãƒ­ãƒ¼ã‚¹)
        hml = params.get('HML', 0)
        if hml > 0.15:
            comments.append("âœ… **ãƒãƒªãƒ¥ãƒ¼æ ªé¸å¥½:** å‰²å®‰æ ªï¼ˆé«˜é…å½“ãƒ»æˆç†Ÿä¼æ¥­ï¼‰ã®å‹•ãã«é€£å‹•ã—ã‚„ã™ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
        elif hml < -0.15:
            comments.append("ğŸš€ **ã‚°ãƒ­ãƒ¼ã‚¹æ ªé¸å¥½:** æˆé•·æ ªï¼ˆãƒã‚¤ãƒ†ã‚¯ãƒ»æ–°èˆˆä¼æ¥­ï¼‰ã®å‹•ãã«å¼·ãé€£å‹•ã—ã¾ã™ã€‚")
        else:
            comments.append("âš–ï¸ **ã‚¹ã‚¿ã‚¤ãƒ«ä¸­ç«‹:** ãƒãƒªãƒ¥ãƒ¼ãƒ»ã‚°ãƒ­ãƒ¼ã‚¹ã®åã‚Šã¯å°‘ãªãã€ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¦ã„ã¾ã™ã€‚")

        # 2. SMB (ã‚µã‚¤ã‚º)
        smb = params.get('SMB', 0)
        if smb > 0.15:
            comments.append("ğŸ£ **å°å‹æ ªåŠ¹æœ:** ä¸­å°å‹æ ªã®å‹•ãã‚’å«ã‚“ã§ãŠã‚Šã€å¸‚å ´å¹³å‡ä»¥ä¸Šã®çˆ†ç™ºåŠ›ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚")
        elif smb < -0.15:
            comments.append("ğŸ˜ **å¤§å‹æ ªå®‰å®š:** å·¨å¤§ä¼æ¥­ä¸­å¿ƒã®æ§‹æˆã§ã€å¸‚å ´ã®å‹•æºã«å¯¾ã—ã¦æ¯”è¼ƒçš„å …ç‰¢ã§ã™ã€‚")
        
        # 3. Mkt-RF (å¸‚å ´æ„Ÿå¿œåº¦)
        mkt = params.get('Mkt-RF', 1.0)
        if mkt > 1.1:
            comments.append("ğŸ¢ **ãƒã‚¤ãƒ™ãƒ¼ã‚¿:** å¸‚å ´å¹³å‡ã‚ˆã‚Šã‚‚å¤§ããå‹•ãã€ç©æ¥µçš„ãªãƒªã‚¹ã‚¯ãƒ†ã‚¤ã‚¯å§¿å‹¢ã§ã™ã€‚")
        elif mkt < 0.9:
            comments.append("ğŸ›¡ï¸ **ãƒ­ãƒ¼ãƒ™ãƒ¼ã‚¿:** å¸‚å ´å…¨ä½“ãŒä¸‹ãŒã£ã¦ã‚‚ã€å‚·ã¯æµ…ãæ¸ˆã‚€ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚·ãƒ–ãªæ§‹æˆã§ã™ã€‚")

        return "\n".join(comments)
